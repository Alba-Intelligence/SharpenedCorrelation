{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4156a7c2",
   "metadata": {},
   "source": [
    "___WORK IN PROGRESS___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928e32d",
   "metadata": {},
   "source": [
    "\n",
    "# Prologue\n",
    "\n",
    "## The Sharpened Cosine Similarity\n",
    "\n",
    "The Sharpened Cosine Similarity is a modified form of cosine distance that showed over the past few months, thought up by Brandon Rohrer .\n",
    "\n",
    "\n",
    "\n",
    "[https://www.rpisoni.dev/posts/cossim-convolution/]()\n",
    "[https://www.rpisoni.dev/posts/cossim-convolution-part2/]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89b29c",
   "metadata": {},
   "source": [
    "The usual cosine transform \n",
    "\n",
    "$$scs(s, k) = \\frac{s \\cdot k}{\\Vert{s}\\Vert \\Vert{k} \\Vert}$$ \n",
    "\n",
    "is modified It looks like\n",
    "\n",
    "$$scs(s, k) = sign(s \\cdot k)\\Biggl(\\frac{s \\cdot k}{(\\Vert{s}\\Vert + q)(\\Vert{k}\\Vert + q)}\\Biggr)^p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365e60e",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "\n",
    "2 Parameters are introduced: \n",
    "\n",
    "- $q$ to floor the value of the norm of either vector;\n",
    "- $p$ an exponentiation factor to decide \n",
    "\n",
    "Let's imagine the case of a picture. Some zones might contain a lot of information (e.g. an airplane); some just noise (e.g. various shades of blue in the background)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290dfbd",
   "metadata": {},
   "source": [
    "### Ignore the irrelevant\n",
    "\n",
    "When running a convolution over the picture, and under the assumption that the entire picture has been normalised, the norm of a patch around the plane will be higher that over the sky. But, when it comes to apply the cosine transform, those local vectors will be renormalised to 1. The effect is that the the convolution filters will be trained to find information assuming that each of those 2 zones are of equal relevance. \n",
    "\n",
    "The $q$ parameter helps. Over a patch of sky, $q$ will be much higher than $\\Vert{s}\\Vert$. Therefore the value of the convolution will be seriously decreased. \n",
    "\n",
    "No training budget will be wasted on training on the useless. $q$ clips the noise out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c6d38",
   "metadata": {},
   "source": [
    "### Focus on anything even remotely interesting, or only zoom in the critical\n",
    "\n",
    "The $p$ exponentiation parameters could be anything from $0^+$ to $+\\infty$.\n",
    "\n",
    "If $p = 1$, we have the normal cosine distance. \n",
    "\n",
    "If $p > 1$, we have a convex function. At the extreme, we have a curve that is almost $0$ almost everywhere until the cosine distance becomes close to $1$. __If $p > 1$, we only look at the truely interesting patches__. __$p > 1$ is super sensitivity__ \n",
    "\n",
    "Conversely, if $p < 1$, we get a concave curve. For very low (positive) values of $p$, the curve will be close to $1$ everywhere until the cosine distance gets close to $0$. __If $p \\rightarrow 0$, the truely useless is ignored, anything else is worth considering__. __$p \\rightarrow 0$ is super specificity__.\n",
    "\n",
    "(P.S. despite decades of exposure to those words, I still reach out to a dictionary to know specificity vs.sensitivity. Intuition A+. Vocabulary. Z-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919de3bf",
   "metadata": {},
   "source": [
    "## How to improve?\n",
    "\n",
    "A few improvements, some implemented in the code, some not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bac98d",
   "metadata": {},
   "source": [
    "### Keep $p$ reasonable (implemented)\n",
    "\n",
    "Instead of using a parameter $p$, use a _Soft ReLU_ shape:\n",
    "\n",
    "$$scs(s, k) = sign(s \\cdot k)\\Biggl(\\frac{s \\cdot k}{(\\Vert{s}\\Vert + q)(\\Vert{k}\\Vert + q)}\\Biggr)^ {\\log \\left( 1 + \\exp \\left( p \\right) \\right) }$$\n",
    "\n",
    "$p$ can now range from $-\\infty$ to $+\\infty$ with the highest gradients around 0, i.e. around an exponent of 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8a254",
   "metadata": {},
   "source": [
    "### Get rid of the cosine transform and go for a real Pearson cross-correlation  (implemented)\n",
    "\n",
    "Cosine distance is great for embeddings. But for determining similarities, not so much. Let's go for a true cross-correlation.\n",
    "\n",
    "$$S = \\sum{s - \\bar{s}}$$\n",
    "$$K = \\sum{k - \\bar{k}}$$\n",
    "\n",
    "$$scs(s, k) = sign(S \\times K))\\Biggl(\\frac{S \\times K}{\\left( \\sqrt{(\\sum{s - \\bar{s})^2}} + q \\right) \\cdot \\left( \\sqrt{(\\sum{k - \\bar{k})^2}} + q \\right)}\\Biggr)^ {\\log \\left( 1 + \\exp \\left( p \\right) \\right) }\n",
    "$$\n",
    "\n",
    "\n",
    "A bit more of a mouthful and would translate into a dog's breakfast in TensorFlow...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81763dad",
   "metadata": {},
   "source": [
    "### Robustify (not implemented)\n",
    "\n",
    "$q$ brings noise removal. But the cross-correlation is still sensitive to outliers. Clipping for example at σ = 2 (Winsorised correlation) after re-normalisation, Spearman or one of myriad other variants with different performance profiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133a8b9",
   "metadata": {},
   "source": [
    "### Use actual information content as the norm  (not implemented)\n",
    "\n",
    "When the Salvator Mundi was put on the market a couple of years ago (and eventually bought for half a billion US), numerous methods were used to confirm its authenticity. An interesting approach came from an AI company that had aplly a similar method to Rembrandt's. See [https://www.art-critique.com/en/2019/04/a-eye-another-tool-for-the-authenticating-artworks/](), on Arxiv [https://arxiv.org/abs/2005.10600]() for a (hardly) little more technical content on Salvator Mundi work, this [https://arxiv.org/abs/1907.12436]() for a bit more, and the code at [https://github.com/stevenjayfrank/A-Eye]().\n",
    "\n",
    "Key to their method method is to focus the training and inference on sections of the painting where the information content is high.\n",
    "\n",
    "This could be use to replace the $q$ parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48320c",
   "metadata": {},
   "source": [
    "# Show me the __Julia__ code\n",
    "\n",
    "Many have contributed TensorFlow and PyTorch implementations. See [https://e2eml.school/scs.html]().\n",
    "\n",
    "Time for some Julia supremacy with the [https://fluxml.ai/](Flux.jl) library. Code is in the repo. Running under Julia 1.7, packages upgraded to the latest versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8683cf2e",
   "metadata": {},
   "source": [
    "## Using the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c0b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Development/julia/projects/SharpenedCorrelation/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "cd(\".\"); using Revise, Pkg; Pkg.activate(\".\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb78d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using BenchmarkTools\n",
    "using Flux\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc3815",
   "metadata": {},
   "source": [
    "We here only use the MNIST dataset described in [https://juliaml.github.io/MLDatasets.jl/stable](). If not already available in `~/.julia/datadeps/`, it will be automatically downloaded. Some `MLDataSets` request accepting the terms of use. If a prompt appears, type `y` + `Enter`.\n",
    "\n",
    "Let's just check that we see something.\n",
    "\n",
    "(To download for example `MNIST` separately: `MNIST.download(; i_accept_the_terms_of_use=true)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59955045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image does not show up in Github\n",
    "using ImageShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7f3b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All errors:\n",
      "===========================================\n",
      "ArgumentError: Package ImageIO [82e4d734-157c-48bb-816b-45c225c6df19] is required but does not seem to be installed:\n",
      " - Run `Pkg.instantiate()` to install all recorded dependencies.\n",
      "\n",
      "===========================================\n",
      "ArgumentError: Package ImageMagick [6218d12a-5da1-5696-b52f-db25d2ecc6d1] is required but does not seem to be installed:\n",
      " - Run `Pkg.instantiate()` to install all recorded dependencies.\n",
      "\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Errors encountered while save FileIO.Stream{FileIO.DataFormat{:PNG}, IOContext{Base64.Base64EncodePipe}, Nothing}(IOContext(Base64.Base64EncodePipe(IOBuffer(data=UInt8[...], readable=true, writable=true, seekable=true, append=false, size=0, maxsize=Inf, ptr=1, mark=-1), Base64.Buffer(UInt8[0x70, 0x27, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xa0, 0x27, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xd0, 0x27, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x00, 0x28, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x30, 0x28, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x60, 0x28, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x90, 0x28, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xc0, 0x28, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x20, 0x29, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x50, 0x29, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x80, 0x29, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xb0, 0x29, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xe0, 0x29, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x40, 0x2a, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x70, 0x2a, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xa0, 0x2a, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xd0, 0x2a, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x00, 0x2b, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x30, 0x2b, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x60, 0x2b, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x90, 0x2b, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xc0, 0x2b, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x20, 0x2c, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x50, 0x2c, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x80, 0x2c, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xb0, 0x2c, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x10, 0x2d, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x40, 0x2d, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x70, 0x2d, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xd0, 0x2d, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x00, 0x2e, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x30, 0x2e, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x60, 0x2e, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x90, 0x2e, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xc0, 0x2e, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xf0, 0x2e, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x50, 0x2f, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x80, 0x2f, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xb0, 0x2f, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xe0, 0x2f, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x40, 0x30, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x70, 0x30, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xa0, 0x30, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xd0, 0x30, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x00, 0x31, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x30, 0x31, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x60, 0x31, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x90, 0x31, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xc0, 0x31, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xf0, 0x31, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x20, 0x32, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x50, 0x32, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x80, 0x32, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xb0, 0x32, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xe0, 0x32, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x10, 0x33, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x40, 0x33, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x70, 0x33, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xa0, 0x33, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0xd0, 0x33, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x00, 0x34, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x30, 0x34, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x60, 0x34, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00, 0x90, 0x34, 0xdf, 0x20, 0x13, 0x7f, 0x00, 0x00], Ptr{UInt8} @0x00007f13211b3110, 0))), nothing).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodError: no method matching save(::FileIO.Stream{FileIO.DataFormat{:PNG}, IOContext{Base64.Base64EncodePipe}, Nothing}, ::Matrix{ColorTypes.Gray{FixedPointNumbers.N0f8}}; mapi=ImageShow.var\"#2#4\"())\n",
      "\u001b[0mClosest candidates are:\n",
      "\u001b[0m  save(\u001b[91m::FileIO.File{FileIO.DataFormat{:PNG}, Name} where Name\u001b[39m, ::Any) at /home/emmanuel/.julia/packages/FileIO/u9YLx/src/mimesave.jl:5\u001b[91m got unsupported keyword argument \"mapi\"\u001b[39m\n",
      "\u001b[0m  save(\u001b[91m::FileIO.File{FileIO.DataFormat{:SVG}, Name} where Name\u001b[39m, ::Any) at /home/emmanuel/.julia/packages/FileIO/u9YLx/src/mimesave.jl:15\u001b[91m got unsupported keyword argument \"mapi\"\u001b[39m\n",
      "\u001b[0m  save(\u001b[91m::FileIO.File{FileIO.DataFormat{:PDF}, Name} where Name\u001b[39m, ::Any) at /home/emmanuel/.julia/packages/FileIO/u9YLx/src/mimesave.jl:25\u001b[91m got unsupported keyword argument \"mapi\"\u001b[39m\n",
      "\u001b[0m  ..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "28×28 reinterpret(reshape, ColorTypes.Gray{FixedPointNumbers.N0f8}, ::Array{N0f8,2}) with eltype ColorTypes.Gray{FixedPointNumbers.N0f8}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fatal error:\n"
     ]
    }
   ],
   "source": [
    "MNIST.convert2image(MNIST.traintensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a5592d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.trainlabels(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488a4e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(MNIST.testtensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c05c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use global variables to easily use other datasets\n",
    "WIDTH, HEIGHT, N_TRAIN_SAMPLE = size(MNIST.traintensor());\n",
    "_, _, N_TEST_SAMPLE = size(MNIST.testtensor());\n",
    "N_CHANNELS = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d0578",
   "metadata": {},
   "source": [
    "Flux helps with the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4add4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = MNIST.traindata(Float32);\n",
    "test_x, test_y = MNIST.testdata(Float32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ae23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a channel dimension for the MNIST dataset\n",
    "train_x = reshape(train_x, WIDTH, HEIGHT, N_CHANNELS, N_TRAIN_SAMPLE);\n",
    "test_x = reshape(test_x, WIDTH, HEIGHT, N_CHANNELS, N_TEST_SAMPLE);\n",
    "\n",
    "# reencode the labels as One-Hot\n",
    "train_y, test_y = Flux.onehotbatch(train_y, 0:9), Flux.onehotbatch(test_y, 0:9);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe1584",
   "metadata": {},
   "source": [
    "`train_x` and `train_y` are functions that deliver the data. They are combined into a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "991ad4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders (mini-batch iterators)\n",
    "BATCH_SIZE = 256;\n",
    "train_loader = Flux.DataLoader((data=train_x, label=train_y), batchsize=BATCH_SIZE, shuffle=true);\n",
    "test_loader = Flux.DataLoader((data=test_x, label=test_y), batchsize=BATCH_SIZE, shuffle=false);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea04da2",
   "metadata": {},
   "source": [
    "## Sharpened Cross-correlation Similarity\n",
    "\n",
    "Let's start building the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47ef57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/Development/julia/projects/SharpenedCorrelation/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.activate(\".\");\n",
    "\n",
    "using Debugger\n",
    "using Flux, MLDatasets, ImageCore, PaddedViews\n",
    "\n",
    "train_x, train_y = MNIST.traindata(Float32);\n",
    "test_x, test_y = MNIST.testdata(Float32);\n",
    "\n",
    "# Let's use global variables to easily use other datasets\n",
    "WIDTH, HEIGHT, N_TRAIN_SAMPLE = size(MNIST.traintensor());\n",
    "_, _, N_TEST_SAMPLE = size(MNIST.testtensor());\n",
    "N_CHANNELS = 1;\n",
    "\n",
    "# Insert a channel dimension for the MNIST dataset\n",
    "train_x = reshape(train_x, WIDTH, HEIGHT, N_CHANNELS, N_TRAIN_SAMPLE);\n",
    "test_x = reshape(test_x, WIDTH, HEIGHT, N_CHANNELS, N_TEST_SAMPLE);\n",
    "\n",
    "# reencode the labels as One-Hot\n",
    "train_y, test_y = Flux.onehotbatch(train_y, 0:9), Flux.onehotbatch(test_y, 0:9);\n",
    "\n",
    "\n",
    "# Create DataLoaders (mini-batch iterators)\n",
    "BATCH_SIZE = 256;\n",
    "train_loader = Flux.DataLoader((data=train_x, label=train_y), batchsize=BATCH_SIZE, shuffle=true);\n",
    "test_loader = Flux.DataLoader((data=test_x, label=test_y), batchsize=BATCH_SIZE, shuffle=false);\n",
    "\n",
    "data, label = first(train_loader);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51a70c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling SharpenedCorrelation [44fb963a-1088-41e2-b5d8-086b29f0560c]\n",
      "└ @ Base loading.jl:1342\n",
      "WARNING: using BenchmarkTools.params in module SharpenedCorrelation conflicts with an existing identifier.\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: LoadError: LoadError: LoadError: \"can't apply finaliser without a reduction\"\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1moutput_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mstore\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[35mTullio\u001b[39m \u001b[90m~/.julia/packages/Tullio/u7Tk0/src/\u001b[39m\u001b[90;4mmacro.jl:782\u001b[0m\n",
      "  [2] \u001b[0m\u001b[1m_tullio\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mexs\u001b[39m::\u001b[0mAny; \u001b[90mmod\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[35mTullio\u001b[39m \u001b[90m~/.julia/packages/Tullio/u7Tk0/src/\u001b[39m\u001b[90;4mmacro.jl:87\u001b[0m\n",
      "  [3] \u001b[0m\u001b[1mvar\"@tullio\"\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90m__source__\u001b[39m::\u001b[0mLineNumberNode, \u001b[90m__module__\u001b[39m::\u001b[0mModule, \u001b[90mexs\u001b[39m::\u001b[0mVararg\u001b[90m{Any, N} where N\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[35mTullio\u001b[39m \u001b[90m~/.julia/packages/Tullio/u7Tk0/src/\u001b[39m\u001b[90;4mmacro.jl:35\u001b[0m\n",
      "  [4] \u001b[0m\u001b[1m#macroexpand#50\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mexpr.jl:112\u001b[0m\u001b[90m [inlined]\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mmacroexpand\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mexpr.jl:111\u001b[0m\u001b[90m [inlined]\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1mdocm\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msource\u001b[39m::\u001b[0mLineNumberNode, \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mmeta\u001b[39m::\u001b[0mAny, \u001b[90mex\u001b[39m::\u001b[0mAny, \u001b[90mdefine\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\u001b[90m (repeats 2 times)\u001b[39m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase.Docs\u001b[39m \u001b[90m./docs/\u001b[39m\u001b[90;4mDocs.jl:537\u001b[0m\n",
      "  [7] \u001b[0m\u001b[1m(::DocStringExtensions.var\"#32#33\"{typeof(DocStringExtensions.template_hook)})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mLineNumberNode, ::\u001b[0mVararg\u001b[90m{Any, N} where N\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[36mDocStringExtensions\u001b[39m \u001b[90m~/.julia/packages/DocStringExtensions/iscC8/src/\u001b[39m\u001b[90;4mtemplates.jl:11\u001b[0m\n",
      "  [8] \u001b[0m\u001b[1mvar\"@doc\"\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90m__source__\u001b[39m::\u001b[0mLineNumberNode, \u001b[90m__module__\u001b[39m::\u001b[0mModule, \u001b[90mx\u001b[39m::\u001b[0mVararg\u001b[90m{Any, N} where N\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mboot.jl:508\u001b[0m\n",
      "  [9] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mBase.jl:384\u001b[0m\n",
      " [10] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[32mSharpenedCorrelation\u001b[39m \u001b[90m~/Development/julia/projects/SharpenedCorrelation/src/\u001b[39m\u001b[90;4mSharpenedCorrelation.jl:1\u001b[0m\n",
      " [11] top-level scope\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m~/Development/julia/projects/SharpenedCorrelation/src/\u001b[39m\u001b[90;4mSharpenedCorrelation.jl:37\u001b[0m\n",
      " [12] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mBase.jl:384\u001b[0m\u001b[90m [inlined]\u001b[39m\n",
      " [13] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt64}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mNothing\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mloading.jl:1235\u001b[0m\n",
      " [14] top-level scope\n",
      "\u001b[90m    @ \u001b[39m\u001b[90;4mnone:1\u001b[0m\n",
      " [15] \u001b[0m\u001b[1meval\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mboot.jl:360\u001b[0m\u001b[90m [inlined]\u001b[39m\n",
      " [16] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mExpr\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @ \u001b[39m\u001b[90mBase.MainInclude\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mclient.jl:446\u001b[0m\n",
      " [17] top-level scope\n",
      "\u001b[90m    @ \u001b[39m\u001b[90;4mnone:1\u001b[0m\n",
      "in expression starting at /home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/model.jl:120\n",
      "in expression starting at /home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/model.jl:105\n",
      "in expression starting at /home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/model.jl:105\n",
      "in expression starting at /home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/SharpenedCorrelation.jl:1\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Failed to precompile SharpenedCorrelation [44fb963a-1088-41e2-b5d8-086b29f0560c] to /home/emmanuel/.julia/compiled/v1.6/SharpenedCorrelation/jl_M4WnMa.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile SharpenedCorrelation [44fb963a-1088-41e2-b5d8-086b29f0560c] to /home/emmanuel/.julia/compiled/v1.6/SharpenedCorrelation/jl_M4WnMa.",
      "",
      "Stacktrace:",
      " [1] error(s::String)",
      "   @ Base ./error.jl:33",
      " [2] compilecache(pkg::Base.PkgId, path::String, internal_stderr::IJulia.IJuliaStdio{Base.PipeEndpoint}, internal_stdout::IJulia.IJuliaStdio{Base.PipeEndpoint}, ignore_loaded_modules::Bool)",
      "   @ Base ./loading.jl:1385",
      " [3] compilecache(pkg::Base.PkgId, path::String)",
      "   @ Base ./loading.jl:1329",
      " [4] _require(pkg::Base.PkgId)",
      "   @ Base ./loading.jl:1043",
      " [5] require(uuidkey::Base.PkgId)",
      "   @ Base ./loading.jl:936",
      " [6] require(into::Module, mod::Symbol)",
      "   @ Base ./loading.jl:923",
      " [7] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [8] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "using SharpenedCorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7862040",
   "metadata": {},
   "source": [
    "Let's create a single Sharpened Cosine Transform with a single B&W input channel yielding 8 output channels. The other 3 parameters are the kernel size, padding width around an image (padded at 0,0), and the stride. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0533a",
   "metadata": {},
   "source": [
    "Setup all the relevant model variables with values (here are the default values taken from [https://github.com/brohrer/sharpened_cosine_similarity_torch/blob/main/demo_cifar10.py]()):\n",
    "\n",
    "- Batch size: `batchsize = 1_024`\n",
    "- Maximum learning rate:  `max_lr = 0.01`\n",
    "- Number of classes: `n_classes = 10`\n",
    "- Number of training epochs: `n_epochs = 100`\n",
    "- Number of runs: `n_runs::Int = 1_000`\n",
    "\n",
    "as well as description of the model layers.\n",
    "\n",
    "`\n",
    "block_params::Dict = Dict(1 => [3,  0, 0, 0, 0, 0],\n",
    "                          2 => [16, 3, 2, 1, 2, 2],\n",
    "                          3 => [24, 3, 2, 1, 2, 2],\n",
    "                          4 => [48, 3, 2, 1, 2, 2])\n",
    "`\n",
    "\n",
    "Here, the model receives input described in layer 1, followed by 3 block layers of _Sharpened Cosine Similarity_ + _Batch Normalisation_ + _Maximum Absolute Pooling_, then followed by a final _linear_ layer (called `MultiDense` in the code) to generate the final classes. \n",
    "\n",
    "Each entry for a dual layer is of the format: `[n_out, scs_kernel, stride, scs_padding, width/height of the max pooling]`. For the input layer 1, the input channels are irrelevant, the layer only generates the input values.\n",
    "\n",
    "Let's start with the smallest model possible, a single layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "035568f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperParameters(256, 10, 100, 500, 0.01f0, Dict(2 => [24, 5, 2, 1, 8], 1 => [1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = HyperParameters(;\n",
    "    batchsize = BATCH_SIZE, \n",
    "    n_classes = size(train_y)[1], \n",
    "    n_epochs = 100, \n",
    "    n_runs = 500, \n",
    "    block_params = Dict(\n",
    "        1 => [1,   0, 0, 0, 0], \n",
    "        2 => [24,  5, 2, 1, 8]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa525675",
   "metadata": {},
   "source": [
    "We create a full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4e65f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating block with output dimension of the SC layer:\n",
      "width in = 28 x height in 28\n",
      "channels in 1 - out channels 24\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SharpenedCorrelationModel(Chain(SharpenedConvolution\n",
       "  W: Array{Float32}((5, 5, 1, 24)) Float32[0.023908557 -0.008969879 … -0.045750722 -0.03180053; 0.0121384505 0.09301324 … -0.017573003 0.007941378; … ; -0.08245261 -0.075111076 … 0.06603708 0.051902246; 0.08674494 0.017567303 … -0.01418195 0.021933129]\n",
       "\n",
       "Float32[0.03907682 -0.0041988944 … 0.040955164 -0.05096256; -0.059918657 0.06120078 … 0.086295426 0.002917473; … ; 0.07604027 0.045576688 … 0.08823348 -0.037430022; 0.08289262 0.0012165267 … -0.00916823 0.07387427]\n",
       "\n",
       "Float32[-0.0060678003 -0.024642838 … 0.03750898 0.056826565; 0.037451398 0.094222225 … 0.06463885 -0.023275241; … ; -0.037248723 -0.08595236 … 0.008826821 0.03380427; -0.00275804 0.06826213 … 0.05995484 -0.061778873]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.08776375 -0.037347887 … 0.0033172355 -0.064650066; -0.04890196 0.082537174 … -0.036455087 0.038408954; … ; -0.08061842 0.037185628 … 0.018836018 0.04791712; 0.04442029 -0.027739787 … 0.041268446 -0.02597773]\n",
       "\n",
       "Float32[-0.060735866 0.03155868 … 0.047199007 -0.056950234; 0.037604194 -0.019363139 … 0.009116745 0.045586664; … ; -0.04150359 -0.09465595 … 0.055748355 -0.06771609; 0.062106453 -0.026371373 … -0.053788837 0.09144531]\n",
       "\n",
       "Float32[0.016094914 0.09764503 … 0.08387048 0.09392039; -0.023547666 0.048991032 … -0.010161901 -0.088615745; … ; 0.03883572 -0.04243099 … -0.07199768 -0.08779891; -0.022995105 -0.014516444 … -0.08935633 0.033068333]\n",
       "  p: Float32 0.0f0\n",
       "  q: Float32 0.1f0\n",
       "  kernel: Int64 5\n",
       "  stride: Int64 2\n",
       "  padding: Int64 1\n",
       "  out_width: Int64 13\n",
       "  out_height: Int64 13\n",
       "  out_chan: Int64 24\n",
       ", BatchNorm(24), AdaptiveMaxPool((8, 8)), flatten, Dense(1536, 10)), HyperParameters(256, 10, 100, 500, 0.01f0, Dict(2 => [24, 5, 2, 1, 8], 1 => [1, 0, 0, 0, 0])), 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SharpenedCorrelationModel(model_params, WIDTH, HEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d74d6",
   "metadata": {},
   "source": [
    "A Flux layer expects the following input dimension: `width` x `height` x `channels` x `batch size`. There for we need to reshape an image before checking that the layer actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23de07a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.870 μs (7 allocations: 3.45 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it works on single image\n",
    "img = @btime train_x[:, :, 1:1, 1:1]\n",
    "size(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4ff9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: Failed to revise /home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/model.jl\n",
      "│   exception = (LoadError(\"/home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/model.jl\", 120, \"can't apply finaliser without a reduction\"), Union{Ptr{Nothing}, Base.InterpreterIP}[])\n",
      "└ @ Revise /home/emmanuel/.julia/packages/Revise/VskYC/src/packagedef.jl:710\n",
      "┌ Warning: The running code does not match the saved version for the following files:\n",
      "│ \n",
      "│   /home/emmanuel/Development/julia/projects/SharpenedCorrelation/src/model.jl\n",
      "│ \n",
      "│ If the error was due to evaluation order, it can sometimes be resolved by calling `Revise.retry()`.\n",
      "│ Use Revise.errors() to report errors again. Only the first error in each file is shown.\n",
      "│ Your prompt color may be yellow until the errors are resolved.\n",
      "└ @ Revise /home/emmanuel/.julia/packages/Revise/VskYC/src/packagedef.jl:818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size W: (5, 5, 1, 24)  --  Size input_patch: (5, 5, 1, 1)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching patch_convolution(::Array{Float32, 4}, ::Array{Float32, 4}, ::Int64, ::Float32, ::Float32, ::Int64)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching patch_convolution(::Array{Float32, 4}, ::Array{Float32, 4}, ::Int64, ::Float32, ::Float32, ::Int64)",
      "",
      "Stacktrace:",
      "  [1] channels_convolution(W::Array{Float32, 4}, input_padded::PaddedView{Float32, 4, NTuple{4, UnitRange{Int64}}, OffsetArrays.OffsetArray{Float32, 4, Array{Float32, 4}}}, k::Int64, p::Float32, q::Float32, v_w::Int64, v_h::Int64, out_c::Int64)",
      "    @ SharpenedCorrelation ~/Development/julia/projects/SharpenedCorrelation/src/model.jl:102",
      "  [2] (::SharpenedCorrelation.var\"#10#11\"{SharpenedConvolution, PaddedView{Float32, 4, NTuple{4, UnitRange{Int64}}, OffsetArrays.OffsetArray{Float32, 4, Array{Float32, 4}}}, Int64})(::Tuple{Int64, Int64, Int64})",
      "    @ SharpenedCorrelation ./none:0",
      "  [3] iterate",
      "    @ ./generator.jl:47 [inlined]",
      "  [4] collect(itr::Base.Generator{Base.Iterators.ProductIterator{Tuple{StepRange{Int64, Int64}, StepRange{Int64, Int64}, UnitRange{Int64}}}, SharpenedCorrelation.var\"#10#11\"{SharpenedConvolution, PaddedView{Float32, 4, NTuple{4, UnitRange{Int64}}, OffsetArrays.OffsetArray{Float32, 4, Array{Float32, 4}}}, Int64}})",
      "    @ Base ./array.jl:681",
      "  [5] (::SharpenedConvolution)(x::Array{Float32, 4})",
      "    @ SharpenedCorrelation ~/Development/julia/projects/SharpenedCorrelation/src/model.jl:170",
      "  [6] applychain(fs::Tuple{SharpenedConvolution, BatchNorm{typeof(identity), Vector{Float32}, Float32, Vector{Float32}}, AdaptiveMaxPool{4, 2}, typeof(flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}, x::Array{Float32, 4})",
      "    @ Flux ~/.julia/packages/Flux/qAdFM/src/layers/basic.jl:47",
      "  [7] (::Chain{Tuple{SharpenedConvolution, BatchNorm{typeof(identity), Vector{Float32}, Float32, Vector{Float32}}, AdaptiveMaxPool{4, 2}, typeof(flatten), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})(x::Array{Float32, 4})",
      "    @ Flux ~/.julia/packages/Flux/qAdFM/src/layers/basic.jl:49",
      "  [8] (::SharpenedCorrelationModel)(x::Array{Float32, 4})",
      "    @ SharpenedCorrelation ~/Development/julia/projects/SharpenedCorrelation/src/model.jl:250",
      "  [9] var\"##core#432\"()",
      "    @ Main ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:489",
      " [10] var\"##sample#433\"(::Tuple{}, __params::BenchmarkTools.Parameters)",
      "    @ Main ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:495",
      " [11] _run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol, Integer, NTuple{4, Symbol}, NamedTuple{(:samples, :evals, :gctrial, :gcsample), Tuple{Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:99",
      " [12] #invokelatest#2",
      "    @ ./essentials.jl:710 [inlined]",
      " [13] #run_result#45",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:34 [inlined]",
      " [14] run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol, Integer, NTuple{5, Symbol}, NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample), Tuple{Bool, Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:117",
      " [15] #warmup#54",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:169 [inlined]",
      " [16] warmup(item::BenchmarkTools.Benchmark)",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:169",
      " [17] top-level scope",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:575",
      " [18] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [19] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# Let's check it doesn't bug out on a single image. Size should be n classes x batch size (here 1)\n",
    "out_label = @btime sc(img)\n",
    "size(out_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eea0d0",
   "metadata": {},
   "source": [
    "## Loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482e89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_and_accuracy(data_loader, model, device)\n",
    "    accuracy = 0\n",
    "    loss = 0.0f0\n",
    "    count = 0\n",
    "    for (x, y) in data_loader\n",
    "        x, y = device(x), device(y)\n",
    "        ŷ = model(x)\n",
    "        loss += Flux.Losses.logitcrossentropy(ŷ, y, agg=sum)\n",
    "        accuracy += sum(onecold(ŷ) .== onecold(y))\n",
    "        count +=  size(x)[end]\n",
    "    end\n",
    "    return loss / count, accuracy / count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b38507b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: model_params not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model_params not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:1",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "optimiser = ADAM(model_params.max_lr);\n",
    "ps = Flux.params(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0969932",
   "metadata": {},
   "source": [
    "## Training - Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41025256",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = first(train_loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaccdb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SharpenedConvolution\n",
       "  W: Array{Float32}((5, 5, 1, 16)) [-0.09097837 -0.07746911 … -0.0782877 0.10234335; -0.07949978 0.035947695 … -0.03898492 0.09566406; … ; -0.031589366 -0.08400774 … -0.118056305 -0.06652068; 0.05039504 0.072273605 … 0.036681302 -0.06439322;;;; 0.06528427 -0.031971585 … -0.014891504 0.021438185; 0.002922749 0.030369377 … -0.030466728 -0.010516672; … ; 0.047203455 -0.06020778 … -0.1088815 0.041800275; -0.012337831 0.0004136222 … 0.020026186 -0.063673384;;;; 0.07209249 -0.11482985 … -0.03032194 -0.078399494; 0.042712264 -0.017164867 … -0.04245942 -0.08434749; … ; -0.053068373 -0.036270924 … -0.01190234 0.04457287; 0.09645407 0.06579522 … 0.08758384 -0.07599504;;;; … ;;;; -0.063273504 -0.044768434 … 0.068598226 0.008047517; -0.04085146 -0.10570993 … 0.08708025 0.017031923; … ; -0.017329399 -0.08272421 … -0.056110084 0.08124348; -0.043610003 -0.08443125 … -0.019943524 -0.112279095;;;; -0.023709128 0.027822658 … 0.024176616 0.02918409; -0.11875814 0.11234228 … 0.01227252 -0.021421798; … ; 0.06870384 -0.106364034 … 0.007173403 0.06393765; 0.040792737 -0.057107314 … -0.03841498 -0.10485477;;;; -0.06500159 -0.022357002 … -0.094185725 -0.06541265; -0.11485138 -0.031750668 … -0.038430534 -0.09678374; … ; -0.09747197 0.04425735 … 0.045868594 0.058573604; 0.08482695 0.030379916 … 0.08272931 -0.10676909]\n",
       "  p: Float32 0.0f0\n",
       "  q: Float32 0.1f0\n",
       "  kernel: Int64 5\n",
       "  stride: Int64 2\n",
       "  padding: Int64 1\n",
       "  out_width: Int64 13\n",
       "  out_height: Int64 13\n",
       "  out_chan: Int64 16\n"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = SharpenedConvolution(WIDTH, HEIGHT, 1, 16, 5, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44016c1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type SharpenedConvolution are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type SharpenedConvolution are not callable",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[75]:1",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "l1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d499cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 12:10:02.643: Failed to load module \"xapp-gtk3-module\"\n",
      "Gtk-Message: 12:10:02.643: Failed to load module \"canberra-gtk-module\"\n"
     ]
    }
   ],
   "source": [
    "using ProfileView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde3616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_warntype l1(data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3847a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gtk.GtkWindowLeaf(name=\"\", parent, width-request=-1, height-request=-1, visible=TRUE, sensitive=TRUE, app-paintable=FALSE, can-focus=FALSE, has-focus=FALSE, is-focus=FALSE, focus-on-click=TRUE, can-default=FALSE, has-default=FALSE, receives-default=FALSE, composite-child=FALSE, style, events=0, no-show-all=FALSE, has-tooltip=FALSE, tooltip-markup=NULL, tooltip-text=NULL, window, opacity=1.000000, double-buffered, halign=GTK_ALIGN_FILL, valign=GTK_ALIGN_FILL, margin-left, margin-right, margin-start=0, margin-end=0, margin-top=0, margin-bottom=0, margin=0, hexpand=FALSE, vexpand=FALSE, hexpand-set=FALSE, vexpand-set=FALSE, expand=FALSE, scale-factor=1, border-width=0, resize-mode, child, type=GTK_WINDOW_TOPLEVEL, title=\"Profile\", role=NULL, resizable=TRUE, modal=FALSE, window-position=GTK_WIN_POS_NONE, default-width=800, default-height=600, destroy-with-parent=FALSE, hide-titlebar-when-maximized=FALSE, icon, icon-name=NULL, screen, type-hint=GDK_WINDOW_TYPE_HINT_NORMAL, skip-taskbar-hint=FALSE, skip-pager-hint=FALSE, urgency-hint=FALSE, accept-focus=TRUE, focus-on-map=TRUE, decorated=TRUE, deletable=TRUE, gravity=GDK_GRAVITY_NORTH_WEST, transient-for, attached-to, has-resize-grip, resize-grip-visible, application, is-active=FALSE, has-toplevel-focus=FALSE, startup-id, mnemonics-visible=FALSE, focus-visible=FALSE, is-maximized=FALSE)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@profview l1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9905af89",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: sc not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: sc not defined",
      "",
      "Stacktrace:",
      "  [1] var\"##core#332\"()",
      "    @ Main ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:489",
      "  [2] var\"##sample#333\"(::Tuple{}, __params::BenchmarkTools.Parameters)",
      "    @ Main ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:495",
      "  [3] _run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Pairs{Symbol, Integer, NTuple{4, Symbol}, NamedTuple{(:samples, :evals, :gctrial, :gcsample), Tuple{Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:99",
      "  [4] #invokelatest#2",
      "    @ ./essentials.jl:718 [inlined]",
      "  [5] #run_result#45",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:34 [inlined]",
      "  [6] run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Pairs{Symbol, Integer, NTuple{5, Symbol}, NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample), Tuple{Bool, Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:117",
      "  [7] #warmup#54",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:169 [inlined]",
      "  [8] warmup(item::BenchmarkTools.Benchmark)",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:169",
      "  [9] top-level scope",
      "    @ ~/.julia/packages/BenchmarkTools/7xSXH/src/execution.jl:575",
      " [10] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [11] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "@btime Flux.Losses.logitcrossentropy(sc(data), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5054e4bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ps not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ps not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[23]:1",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "gradient(() -> Flux.Losses.logitcrossentropy(sc(data), label), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f89a511e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ps not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ps not defined",
      "",
      "Stacktrace:",
      " [1] macro expansion",
      "   @ In[24]:11 [inlined]",
      " [2] top-level scope",
      "   @ ~/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:940",
      " [3] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "# Work in progress.\n",
    "\n",
    "## Training\n",
    "# @showprogress for epoch in 1:model_params.n_epochs\n",
    "@showprogress for epoch in 1:2\n",
    "    for (data, label) in train_loader\n",
    "        # Transfer data to device - Uncomment to use automatic detection in the package\n",
    "        # data, label = SCS.Training_Device(data), SCS.Training_Device(label) \n",
    "        \n",
    "        # Compute gradient\n",
    "        gs = gradient(() -> Flux.Losses.logitcrossentropy(sc(data), label), ps) \n",
    "        Flux.Optimise.update!(optimiser, ps, gs) # update parameters\n",
    "    end\n",
    "\n",
    "    # Report on train and test\n",
    "    train_loss, train_acc = loss_and_accuracy(train_loader, scs, SCS.Training_Device)\n",
    "    test_loss, test_acc = loss_and_accuracy(test_loader, scs_model, SCS.Training_Device)\n",
    "    println(\"Epoch: $(epoch) / $(model_params.n_epochs)\")\n",
    "    println(\"  train_loss = $(train_loss), train_accuracy = $(train_acc)\")\n",
    "    println(\"  test_loss = $(test_loss), test_accuracy = $(test_acc)\")\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "351px",
    "width": "377px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
